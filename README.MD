# Deploying Hadoop and Spark on Raspberry Pi Cluster

## Introduction
This a step-by-step instruction on how to deploying the distributed computing system Hadoop and Spark on a n-node Raspberry Pi cluster. It is a great practice that get you familiar with the setups and functions of the distributed computing system. If you are interested in Data Engineering with direct access to cloud computing system such AWS, this setups would a great portable alternatives.

## Basic Setups of the Cluster
To balance between cost and performance, I chose four Raspberry Pi 4B as the basic nodes. I plan to expand my cluster to 8 nodes with additional Raspberry Pis.

### Specs of Respberry Pi 4 Cluster:
  * 1.5GHz 4-core CPU with 4GB memory
  * 32 GB Samsung EVO microSD
  * PoE HAT
  * Unifi 8 Port Switch 60W
  * OS Raspbian Lite

## Security

## Connection

## Hadoop

## Spark

## Steps

## Final thoughts

## Reference
