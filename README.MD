# Deploying Hadoop and Spark on Raspberry Pi Cluster

## Introduction
This a step-by-step instruction on how to deploying the distributed computing system Hadoop and Spark on a n-node Raspberry Pi cluster. It is a great practice that get you familiar with the setups and functions of the distributed computing system. If you are interested in Data Engineering with direct access to cloud computing system such AWS, this setups would a great portable alternatives.

## Basic Setups
To balance between cost and performance, I chose four Raspberry Pi 4B as the basic nodes. I plan to expand my cluster to 8 nodes with additional Raspberry Pis.

### Specs and cost of Respberry Pi 4 Cluster:
  * 1.5GHz 4-core CPU with 4GB memory ($57 each)
  * 32 GB Samsung EVO microSD ($7 each)
  * PoE HAT ($20 each)
  * Unifi 8 Port Switch 60W ($112)
  * Raspbian Lite OS (surprisingly free)
  * GeekPi cluster case ($39.99 not recommended)
  * 4 1-feet ethernet cables ($10)

## Security

## Connection

## Hadoop

## Spark

## Steps

## Final thoughts

## Reference
